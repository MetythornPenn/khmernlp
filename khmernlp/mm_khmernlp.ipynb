{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15drZwEphMzR"
      },
      "source": [
        "# Word segmentation using Maximal Matching\n",
        "apply this concept from nmm_pythainl research in Thai language"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnz873rCjwdH"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y1lHieGehKW5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from heapq import heappush, heappop  # for priority queue\n",
        "\n",
        "!pip install -q marisa_trie\n",
        "from marisa_trie import Trie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert data from excel to txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget nv https://huggingface.co/datasets/metythorn/khmer-dictionary-dataset-44k-v1/blob/main/khmer_dictionary.xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If u got error when loading excel let try download directly from huggingface url above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t_main</th>\n",
              "      <th>t_pron</th>\n",
              "      <th>t_poly</th>\n",
              "      <th>t_pos</th>\n",
              "      <th>t_exp</th>\n",
              "      <th>t_exam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ក</td>\n",
              "      <td>[ក]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ន.</td>\n",
              "      <td>តួព្យញ្ជនៈទី១នៃអក្ខរក្រមព្យញ្ជនៈខ្មែរ និងជាតួព...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ក</td>\n",
              "      <td>[ក]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>កិ.</td>\n",
              "      <td>តាំងផ្ដើម, តាំងធ្វើ :</td>\n",
              "      <td>កសាង, កកើត, កចេតិយ, កភូមិ។</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ក</td>\n",
              "      <td>[ក]</td>\n",
              "      <td>១)</td>\n",
              "      <td>ន.</td>\n",
              "      <td>អវយវៈដែលតពីក្បាលទៅស្មាឬទៅខ្លួននៃមនុស្សសត្វ :</td>\n",
              "      <td>កមនុស្ស, កមាន់។</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ក</td>\n",
              "      <td>[ក]</td>\n",
              "      <td>២)</td>\n",
              "      <td>ន.</td>\n",
              "      <td>កន្លែងដែលតជាប់ពីមាត់ដបជាដើមចុះទៅទល់នឹងក្អេងក៏ហ...</td>\n",
              "      <td>កដប, កក្អម។</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ក</td>\n",
              "      <td>[ក]</td>\n",
              "      <td>៣)</td>\n",
              "      <td>ន.</td>\n",
              "      <td>ផ្នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃឬពីប...</td>\n",
              "      <td>កដៃ, កជើង។</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  t_main t_pron t_poly t_pos  \\\n",
              "0      ក    [ក]    NaN    ន.   \n",
              "1      ក    [ក]    NaN   កិ.   \n",
              "2      ក    [ក]     ១)    ន.   \n",
              "3      ក    [ក]     ២)    ន.   \n",
              "4      ក    [ក]     ៣)    ន.   \n",
              "\n",
              "                                               t_exp  \\\n",
              "0  តួព្យញ្ជនៈទី១នៃអក្ខរក្រមព្យញ្ជនៈខ្មែរ និងជាតួព...   \n",
              "1                              តាំងផ្ដើម, តាំងធ្វើ :   \n",
              "2       អវយវៈដែលតពីក្បាលទៅស្មាឬទៅខ្លួននៃមនុស្សសត្វ :   \n",
              "3  កន្លែងដែលតជាប់ពីមាត់ដបជាដើមចុះទៅទល់នឹងក្អេងក៏ហ...   \n",
              "4  ផ្នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃឬពីប...   \n",
              "\n",
              "                       t_exam  \n",
              "0                         NaN  \n",
              "1  កសាង, កកើត, កចេតិយ, កភូមិ។  \n",
              "2             កមនុស្ស, កមាន់។  \n",
              "3                 កដប, កក្អម។  \n",
              "4                  កដៃ, កជើង។  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load excel file using pandas\n",
        "import pandas as pd\n",
        "df = pd.read_excel('./khmer_dictionary.xlsx', engine='openpyxl')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_word = df[\"t_main\"]\n",
        "# remove duplicate words\n",
        "df_word = df_word.drop_duplicates()\n",
        "# convert to text file by support khmer language\n",
        "df_word.to_csv(\"khmer_dictionary.txt\", index=False, header=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8qOGjNIoEIh"
      },
      "source": [
        "## Load Data\n",
        "load khmer_dictionary.txt to create trie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nskwTCK3kBX5"
      },
      "outputs": [],
      "source": [
        "wordlist = [li.strip() for li in open('./khmer_dictionary.txt', 'r', encoding='utf-8')]\n",
        "trie = Trie(wordlist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['កក់', 'កក់ក្ដៅ']\n",
            "['កា', 'ការ', 'ការិយាធិបតេយ្យ', 'ការិយាល័យ', 'ការិយកម្ម', 'ការិយបរិច្ឆេទ', 'ការិនី', 'ការុញ្ញចិត្ត', 'ការុញ្ញភាព', 'ការុញ្ញហេតុ', 'ការុង', 'ការុណិក', 'ការបង្កើតថ្មី', 'ការបន្តពូជ', 'ការប៉ះទង្គិច', 'ការប្រាក់', 'ការពារ', 'ការពារប្រទេស', 'ការពិត', 'ការកនាម', 'ការកេត', 'ការណនិយម', 'ការណ៍', 'ការី', 'ការីម៉ាឃិធីង', 'ការងារ', 'ការជួល', 'ការដ្ឋាន', 'ការទូត', 'ការន្ត', 'ការរញ្ជួយដី', 'ការាត់', 'ការ៉ាតេដូ', 'ការ៉ាស់', 'ការ៉ូ', 'ការ៉ូឡា', 'ការ៉ុត', 'ការ៉េ', 'ការ៉េម', 'ការ៉េមកី', 'ការ្យ', 'ការ្យសិល្បៈ', 'ការ៍ទូស', 'កាត', 'កាត់', 'កាត់កង', 'កាត់កាល់', 'កាត់ក្ដី', 'កាត់សក់', 'កាត់សាញ', 'កាត់ស្បែក', 'កាត់ទឹក', 'កាត់ទោស', 'កាត់ចុង', 'កាត់ដេរ', 'កាត់ថ្លៃ', 'កាតៅ', 'កាតំ', 'កាតាលីកម្ម', 'កាតាលីករ', 'កាតាក', 'កាតាប', 'កាតាឡុក', 'កាតឹប', 'កាតឹបស៊ង', 'កាតគ្រី', 'កាតព្វកិច្ច', 'កាតិក', 'កាតុង', 'កាតូដ', 'កាប', 'កាប៊ីន', 'កាប៊ីនភ្លើង', 'កាប៊ីណេត៍', 'កាប់', 'កាប់ឆៅ', 'កាប់ស្តាំង', 'កាប៉ូរ៉ាល់', 'កាប៉ៅ', 'កាបែន', 'កាប៌ាស', 'កាបៗ', 'កាបូន', 'កាបូនឌីអុកស៊ីដ', 'កាបូនម៉ូណូអុកស៊ីដ', 'កាបូនអ៊ីដ្រាត', 'កាបូនីល', 'កាបូប', 'កាល', 'កាលប្រវត្តិ', 'កាលប្រវត្តិវិទ្យា', 'កាលប្បវត្តិ', 'កាលបរិច្ឆេទ', 'កាលវិទ្យា', 'កាលវិភាគ', 'កាលវសាន', 'កាលកិរិយា', 'កាលកំណត់', 'កាលានុវត្តនិយម', 'កាលានុវត្តភាព', 'កាលិក', 'កាលិកបត្រ', 'កាលដែល', 'កាលសម័យ', 'កាលៈទេសៈ', 'កាល់', 'កាក', 'កាកបាទ', 'កាកបាទក្រហម', 'កាកគតិ', 'កាកណិក', 'កាកនាសូរ', 'កាកសំណល់', 'កាកអំពៅ', 'កាកាវ', 'កាកី', 'កាក់', 'កាក់កប', 'កាក់ទុក', 'កាក់ល្អិត', 'កាក់ៗ', 'កាយ', 'កាយវិកល', 'កាយវិការ', 'កាយវិញ្ញាណ', 'កាយវិភាគវិទ្យា', 'កាយវប្បកម្ម', 'កាយសម្បទា', 'កាយសម្ផស្ស', 'កាយសម្ព័ន្ធ', 'កាយសិក្សា', 'កាយសុចរិត', 'កាយពល', 'កាយរូបារម្មណ៍', 'កាយឫទ្ធិ', 'កាយ—', 'កាឡា', 'កាឡាប៉ា', 'កាឡាម', 'កាឡារូប', 'កាឡាសូរ', 'កាឡូរី', 'កាឡូរីមេទ្រី', 'កាឡូរីម៉ែត្រ', 'កាឡូរីមាត្រសាស្ត្រ', 'កាឡកណ្ណី', 'កាឡកិណី', 'កាឡី', 'កាឡេ', 'កាឡៃ', 'កាន', 'កាន់', 'កាន់កាប់', 'កាន់ការ', 'កាន់សាសនា', 'កាន់សីល', 'កាន់អង្គ', 'កាន់អំណាច', 'កាន់ខែ', 'កាន់ចង្កូត', 'កាន់ជើង', 'កាន់តែ', 'កាន់ទុក្ខ', 'កាច', 'កាច់', 'កាច់ចង្កូត', 'កាច់ចង្កេះ', 'កាច់កុង', 'កាច់ជ្រុង', 'កាច់រាង', 'កាច់សង្រែក', 'កាច់ឫក', 'កាចា', 'កាចុង', 'កាព្យ', 'កាព្យនិទាន', 'កាព្យមាត្រ', 'កាព្យរស', 'កាព្យសាស្ត្រ', 'កាពិ', 'កាពិផាវ', 'កាពិផៅ', 'កាពីទែន', 'កាម', 'កាមរូបារម្មណ៍', 'កាមរោគ', 'កាមតណ្ហា', 'កាមទេព', 'កាម៉ុង', 'កាម៉្ញុង', 'កាមេរ៉ា', 'កាម—', 'កាស', 'កាស៊ីណូ', 'កាស៊ីណូម', 'កាស្កែត', 'កាស្សែត', 'កាសែត', 'កាសាវពស្ត្រ', 'កាសាវភស្ត្រ', 'កាសអង្ករ', 'កាណាល់', 'កាណុង', 'កាណូត', 'កាណ៌', 'កាហែ', 'កាហោ', 'កាហ្វេ', 'កាហាត', 'កាដូ', 'កាដ្រង់', 'កាខែកកាខោក', 'កាគី', 'កាង', 'កាញ់', 'កាឌីណាល់', 'កាផែ', 'កាវ', 'កាំ', 'កាំបិត', 'កាំបិតស្នៀត', 'កាំប្រមា', 'កាំប្រាក់', 'កាំជ្រួច', 'កាំជ្រួចទឹកក្ដៅ', 'កាំភ្លើង', 'កាំភ្លោះ', 'កាំរន្ទះ', 'កាំរស្មី', 'កាំពន្លឺ', 'កាំម្រឹត']\n",
            "231\n",
            "====== dataset info ======\n",
            "<class 'marisa_trie.Trie'>\n",
            "25285\n"
          ]
        }
      ],
      "source": [
        "# check dataset \n",
        "print(trie.keys(u'កក់'))\n",
        "print(trie.keys(u'កា'))\n",
        "print(len(trie.keys(u'កា')))\n",
        "\n",
        "print(\"====== dataset info ======\")\n",
        "print(type(trie))\n",
        "print(len(trie))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbF5DamyoWWY"
      },
      "source": [
        "## One Cut\n",
        "แทนที่ multicut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sZnWecX5n_gt"
      },
      "outputs": [],
      "source": [
        "# help segmenet enlish word also\n",
        "pat_eng = re.compile(r'''(?x)\n",
        "[-a-zA-Z]+|   # english\n",
        "\\d[\\d,\\.]*|   # number\n",
        "[ \\t]+|       # space\n",
        "\\r?\\n         # newline\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vvrSyr8ppMfz"
      },
      "outputs": [],
      "source": [
        "# text = 'สวัสดีครับ สบายดีไหมครับ'\n",
        "# creae text variable with khmer sentence\n",
        "text = \"ផ្នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t1KpSfXjpIzS"
      },
      "outputs": [],
      "source": [
        "def onecut(text):\n",
        "  words_at = defaultdict(list)  # main data structure\n",
        "\n",
        "  def serialize(p, p2):    # helper function\n",
        "    for w in words_at[p]:\n",
        "      p_ = p + len(w)\n",
        "      if p_== p2:\n",
        "        yield [w]\n",
        "      elif p_ < p2:\n",
        "        for path in serialize(p_, p2):\n",
        "          yield [w]+path\n",
        "\n",
        "  q = [0]       # min-heap queue\n",
        "  last_p = 0    # last position for yield\n",
        "  while q[0] < len(text):\n",
        "      p = heappop(q)\n",
        "\n",
        "      for w in trie.prefixes(text[p:]):\n",
        "          words_at[p].append(w)\n",
        "          if p+len(w) not in q:\n",
        "            heappush(q, p+len(w))\n",
        "\n",
        "      if len(q)==1:\n",
        "          for w in min(serialize(last_p, q[0]), key=len):\n",
        "            yield w\n",
        "          last_p = q[0]\n",
        "\n",
        "      # กรณี len(q) == 0  คือ ไม่มีใน dict\n",
        "      if len(q)==0:\n",
        "          m = pat_eng.match(text[p:])\n",
        "          if m: # อังกฤษ, เลข, ว่าง\n",
        "              i = p + m.span()[1]\n",
        "          else: # skip น้อยที่สุด ที่เป็นไปได้\n",
        "              for i in range(p, len(text)):\n",
        "                  ww = trie.prefixes(text[i:])\n",
        "                  m = pat_eng.match(text[i:])\n",
        "                  if ww or m:\n",
        "                      break\n",
        "              else:\n",
        "                  i = len(text)\n",
        "          w = text[p:i]\n",
        "          words_at[p].append(w)\n",
        "          yield w\n",
        "          last_p = i\n",
        "          heappush(q, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkv6s-gu1aCN"
      },
      "source": [
        "### heapq แทน set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0GFIwF0S1Ugx",
        "outputId": "e4a1de12-d095-4c0c-83c3-7d3752e4c898"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 4, 9, 5]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = []   # min heap queue\n",
        "for x in [4, 9, 2, 1, 5]:\n",
        "  heappush(q, x)\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "u4ryMECP3Hwn",
        "outputId": "14fe5ccf-3ac7-4a94-8e9d-ef9ed428ab3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min of queue is 1\n"
          ]
        }
      ],
      "source": [
        "print(\"min of queue is\", q[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "qkqb__w-20uJ",
        "outputId": "060390cf-627f-4619-bea4-e78a587d16b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "4\n",
            "5\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "while q:\n",
        "  print(heappop(q))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh2iZfSicoJr"
      },
      "source": [
        "### Manual loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mSTdQOpZcrCu"
      },
      "outputs": [],
      "source": [
        "words_at = defaultdict(list)\n",
        "q = [0]\n",
        "last_p = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "INkfWE0Fcq-m",
        "outputId": "fbd58279-6c18-411d-8277-03fae00cc276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1, 5]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# manual instead of while loop\n",
        "print(q[0])\n",
        "p = heappop(q)\n",
        "\n",
        "for w in trie.prefixes(text[p:]):\n",
        "  words_at[p].append(w)\n",
        "  if p+len(w) not in q:\n",
        "    heappush(q, p+len(w))\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "E3ITMYSXMjS0",
        "outputId": "17a2530c-3494-4a7f-e88a-e9fb69c2b2da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ส, สว\n",
        "'ផ្នែក' in wordlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "xKYBEKaMMu9d",
        "outputId": "3c736320-05dc-4811-8f47-9b14947474c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[5]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(q[0])\n",
        "p = heappop(q)\n",
        "\n",
        "for w in trie.prefixes(text[p:]):\n",
        "  words_at[p].append(w)\n",
        "  if p+len(w) not in q:\n",
        "    heappush(q, p+len(w))\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "CNGJ-EsaNeAy",
        "outputId": "fb3067dc-caf8-4493-e432-3500b16fd7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[6, 7]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(q[0])\n",
        "p = heappop(q)\n",
        "\n",
        "for w in trie.prefixes(text[p:]):\n",
        "  words_at[p].append(w)\n",
        "  if p+len(w) not in q:\n",
        "    heappush(q, p+len(w))\n",
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YCP9iUFHNs6q",
        "outputId": "5ad67f70-7595-475a-c9b6-610ecb7ff937"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 6)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if len(q) == 1:\n",
        "#   q0 = q[0]\n",
        "#   yield LatticeString(text[last_p:q0], serialize(last_p, q0))\n",
        "#   last_p = q0\n",
        "last_p, q[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "a1iwoO1COOYw",
        "outputId": "7ad4e293-7e19-4afb-9d16-8e608d2a0dbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(list, {0: ['ផ', 'ផ្នែក'], 5: ['ន', 'នៃ']})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_at"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iyC9PQQrRH"
      },
      "source": [
        "### mm_path\n",
        "ปรับจาก LatticeString ที่รวมทุกๆ path มาเป็น min แค่ path เดียว"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OnLIq_zIQxTc"
      },
      "outputs": [],
      "source": [
        "def serialize(p, p2):    # helper function\n",
        "  for w in words_at[p]:\n",
        "    p_ = p + len(w)\n",
        "    if p_== p2:\n",
        "      yield [w]\n",
        "    elif p_ < p2:\n",
        "      for path in serialize(p_, p2):\n",
        "        yield [w]+path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dOQ-ZdRJRFBe",
        "outputId": "8daab180-b1b4-4ef9-fd63-7711e4d1bf55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ផ្នែក', 'ន']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# maximal path ก็คือใช้ len เป็นตัวเลือก\n",
        "min(serialize(0,6), key=len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2T7gNKSaAFT"
      },
      "source": [
        "ทดลองเสร็จแล้ว ก็ไปแก้ใน one cut ด้านบน"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tlRicYuaMM4"
      },
      "source": [
        "## ทดลอง"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Z9Fzlc3dQGIM",
        "outputId": "8a5ae8ee-ee11-4933-b6df-7f550f1f2938"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ផ្នែក',\n",
              " 'នៃ',\n",
              " 'ដៃ',\n",
              " 'ឬ',\n",
              " 'ជើង',\n",
              " 'ដែល',\n",
              " 'តភ្ជាប់',\n",
              " 'ពី',\n",
              " 'ប្រអប់ដៃ',\n",
              " 'ទៅ',\n",
              " 'កំភួនដៃ']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(onecut('ផ្នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃ'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from heapq import heappush, heappop  # for priority queue\n",
        "from marisa_trie import Trie\n",
        "\n",
        "wordlist = [li.strip() for li in open('./khmer_words.txt', 'r', encoding='utf-8')]\n",
        "trie = Trie(wordlist)\n",
        "\n",
        "# ช่วยตัดพวกภาษาอังกฤษ เป็นต้น\n",
        "pat_eng = re.compile(r'''(?x)\n",
        "[-a-zA-Z]+|   # english\n",
        "\\d[\\d,\\.]*|   # number\n",
        "[ \\t]+|       # space\n",
        "\\r?\\n         # newline\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def onecut(text):\n",
        "  words_at = defaultdict(list)  # main data structure\n",
        "\n",
        "  def serialize(p, p2):    # helper function\n",
        "    for w in words_at[p]:\n",
        "      p_ = p + len(w)\n",
        "      if p_== p2:\n",
        "        yield [w]\n",
        "      elif p_ < p2:\n",
        "        for path in serialize(p_, p2):\n",
        "          yield [w]+path\n",
        "\n",
        "  q = [0]       # min-heap queue\n",
        "  last_p = 0    # last position for yield\n",
        "  while q[0] < len(text):\n",
        "      p = heappop(q)\n",
        "\n",
        "      for w in trie.prefixes(text[p:]):\n",
        "          words_at[p].append(w)\n",
        "          if p+len(w) not in q:\n",
        "            heappush(q, p+len(w))\n",
        "\n",
        "      if len(q)==1:\n",
        "          for w in min(serialize(last_p, q[0]), key=len):\n",
        "            yield w\n",
        "          last_p = q[0]\n",
        "\n",
        "      # กรณี len(q) == 0  คือ ไม่มีใน dict\n",
        "      if len(q)==0:\n",
        "          m = pat_eng.match(text[p:])\n",
        "          if m: # อังกฤษ, เลข, ว่าง\n",
        "              i = p + m.span()[1]\n",
        "          else: # skip น้อยที่สุด ที่เป็นไปได้\n",
        "              for i in range(p, len(text)):\n",
        "                  ww = trie.prefixes(text[i:])\n",
        "                  m = pat_eng.match(text[i:])\n",
        "                  if ww or m:\n",
        "                      break\n",
        "              else:\n",
        "                  i = len(text)\n",
        "          w = text[p:i]\n",
        "          words_at[p].append(w)\n",
        "          yield w\n",
        "          last_p = i\n",
        "          heappush(q, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['សួស', '្', 'តី', 'ឆ្នាំ', 'ថ្មី', '។']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(onecut('សួស្តីឆ្នាំថ្មី។'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ឥឦឧឨឩឪឫឬឭឮឯឰឱឲឳ឴឵ាិីឹឺុូួើឿៀេែៃោៅំះៈ\n"
          ]
        }
      ],
      "source": [
        "khmer_vowels_string = ''.join([\n",
        "    \"\\u17A5\", \"\\u17A6\", \"\\u17A7\", \"\\u17A8\", \"\\u17A9\",\n",
        "    \"\\u17AA\", \"\\u17AB\", \"\\u17AC\", \"\\u17AD\", \"\\u17AE\",\n",
        "    \"\\u17AF\", \"\\u17B0\", \"\\u17B1\", \"\\u17B2\", \"\\u17B3\",\n",
        "    \"\\u17B4\", \"\\u17B5\", \"\\u17B6\", \"\\u17B7\", \"\\u17B8\",\n",
        "    \"\\u17B9\", \"\\u17BA\", \"\\u17BB\", \"\\u17BC\", \"\\u17BD\",\n",
        "    \"\\u17BE\", \"\\u17BF\", \"\\u17C0\", \"\\u17C1\", \"\\u17C2\",\n",
        "    \"\\u17C3\", \"\\u17C4\", \"\\u17C5\", \"\\u17C6\", \"\\u17C7\",\n",
        "    \"\\u17C8\",\n",
        "    \n",
        "])\n",
        "\n",
        "print(khmer_vowels_string)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr-CCHgIaups"
      },
      "source": [
        "## รวม TCC\n",
        "หลักคือ คำนวณ tcc position ก่อน และสร้าง edge เฉพาะที่ลงพอดีตำแหน่งกัน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LN8-Gf7paLXc"
      },
      "outputs": [],
      "source": [
        "pat_tcc = \"\"\"\\\n",
        "เc็c\n",
        "เcctาะ\n",
        "เccีtยะ\n",
        "เccีtย(?=[เ-ไก-ฮ]|$)\n",
        "เccอะ\n",
        "เcc็c\n",
        "เcิc์c\n",
        "เcิtc\n",
        "เcีtยะ?\n",
        "เcืtอะ?\n",
        "เc[ิีุู]tย(?=[เ-ไก-ฮ]|$)\n",
        "เctา?ะ?\n",
        "cัtวะ\n",
        "c[ัื]tc[ุิะ]?\n",
        "c[ิุู]์\n",
        "c[ะ-ู]t\n",
        "c็\n",
        "ct[ะาำ]?\n",
        "แc็c\n",
        "แcc์\n",
        "แctะ\n",
        "แcc็c\n",
        "แccc์\n",
        "โctะ\n",
        "[เ-ไ]ct\n",
        "\"\"\".replace('c','[ก-ฮ]').replace('t', '[่-๋]?').split()\n",
        "\n",
        "def tcc(w):\n",
        "    p = 0\n",
        "    pat = re.compile(\"|\".join(pat_tcc))\n",
        "    while p<len(w):\n",
        "        m = pat.match(w[p:])\n",
        "        if m:\n",
        "            n = m.span()[1]\n",
        "        else:\n",
        "            n = 1\n",
        "        yield w[p:p+n]\n",
        "        p += n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Cx0fk3I2dBeY",
        "outputId": "988e3752-8714-49c1-e3e2-fdc508ceafd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ផ',\n",
              " '្',\n",
              " 'ន',\n",
              " 'ែ',\n",
              " 'ក',\n",
              " 'ន',\n",
              " 'ៃ',\n",
              " 'ដ',\n",
              " 'ៃ',\n",
              " 'ឬ',\n",
              " 'ជ',\n",
              " 'ើ',\n",
              " 'ង',\n",
              " 'ដ',\n",
              " 'ែ',\n",
              " 'ល',\n",
              " 'ត',\n",
              " 'ភ',\n",
              " '្',\n",
              " 'ជ',\n",
              " 'ា',\n",
              " 'ប',\n",
              " '់',\n",
              " 'ព',\n",
              " 'ី',\n",
              " 'ប',\n",
              " '្',\n",
              " 'រ',\n",
              " 'អ',\n",
              " 'ប',\n",
              " '់',\n",
              " 'ដ',\n",
              " 'ៃ',\n",
              " 'ទ',\n",
              " 'ៅ',\n",
              " 'ក',\n",
              " 'ំ',\n",
              " 'ភ',\n",
              " 'ួ',\n",
              " 'ន',\n",
              " 'ដ',\n",
              " 'ៃ']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(tcc(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SCsxZk_kdMe-",
        "outputId": "bc5f5b8b-21e4-45d3-b6d0-fcbe71190b16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ตำแหน่งที่อนุญาตให้ตัดได้\n",
        "def tcc_pos(text):\n",
        "  p_set = set()\n",
        "  p = 0\n",
        "  for w in tcc(text):\n",
        "    p += len(w)\n",
        "    p_set.add(p)\n",
        "  return p_set\n",
        "\n",
        "tcc_pos(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sLVEcRsweDHt"
      },
      "outputs": [],
      "source": [
        "def mmcut(text):\n",
        "  return list(onecut(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZzEDlaSyeLJe",
        "outputId": "a0587b7a-3c54-47d0-b980-fdf538b96ad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ផ្នែក',\n",
              " 'នៃ',\n",
              " 'ដៃ',\n",
              " 'ឬ',\n",
              " 'ជើង',\n",
              " 'ដែល',\n",
              " 'តភ្ជាប់',\n",
              " 'ពី',\n",
              " 'ប្រអប់ដៃ',\n",
              " 'ទៅ',\n",
              " 'កំភួនដៃ']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ตัวอย่างปัญหา ไม่ควร add 'จุ' เพราะไม่ตรง tcc_pos\n",
        "mmcut('ផ្នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fD6feW2VfY6Y"
      },
      "outputs": [],
      "source": [
        "# แยก serialize ออกมา จะได้อ่าน code ง่ายขึ้น\n",
        "def serialize(words_at, p, p2):\n",
        "  # find path แบบ depth first\n",
        "  for w in words_at[p]:\n",
        "    p_ = p + len(w)\n",
        "    if p_== p2:\n",
        "      yield [w]\n",
        "    elif p_ < p2:\n",
        "      for path in serialize(words_at, p_, p2):\n",
        "        yield [w]+path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8F1FiG5Xd63b"
      },
      "outputs": [],
      "source": [
        "# ปรับ onecut ให้ใช้ tcc_pos\n",
        "def onecut(text):\n",
        "  words_at = defaultdict(list)  # main data structure\n",
        "  allow_pos = tcc_pos(text)\n",
        "\n",
        "  q = [0]       # min-heap queue\n",
        "  last_p = 0    # last position for yield\n",
        "  while q[0] < len(text):\n",
        "      p = heappop(q)\n",
        "\n",
        "      for w in trie.prefixes(text[p:]):\n",
        "          p_ = p + len(w)\n",
        "          if p_ in allow_pos:  # เลือกที่สอดคล้อง tcc\n",
        "            words_at[p].append(w)\n",
        "            if p_ not in q:\n",
        "              heappush(q, p_)\n",
        "\n",
        "      if len(q)==1:\n",
        "          paths = serialize(words_at, last_p, q[0])\n",
        "          for w in min(paths, key=len):\n",
        "            yield w\n",
        "          last_p = q[0]\n",
        "\n",
        "      # กรณี len(q) == 0  คือ ไม่มีใน dict\n",
        "      if len(q)==0:\n",
        "          m = pat_eng.match(text[p:])\n",
        "          if m: # อังกฤษ, เลข, ว่าง\n",
        "              i = p + m.end()\n",
        "          else: # skip น้อยที่สุด ที่เป็นไปได้\n",
        "              for i in range(p, len(text)):\n",
        "                  if i in allow_pos:   # ใช้ tcc ด้วย\n",
        "                      ww = trie.prefixes(text[i:])\n",
        "                      m = pat_eng.match(text[i:])\n",
        "                      if ww or m:\n",
        "                          break\n",
        "              else:\n",
        "                  i = len(text)\n",
        "          w = text[p:i]\n",
        "          words_at[p].append(w)\n",
        "          yield w\n",
        "          last_p = i\n",
        "          heappush(q, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SQpYZNpzjG4w",
        "outputId": "6f91e60a-9bff-45cb-8e6e-d9cd385b1eaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ផ្នែក',\n",
              " 'នៃ',\n",
              " 'ដៃ',\n",
              " 'ឬ',\n",
              " 'ជើង',\n",
              " 'ដែល',\n",
              " 'តភ្ជាប់',\n",
              " 'ពី',\n",
              " 'ប្រអប់ដៃ',\n",
              " 'ទៅ',\n",
              " 'កំភួនដៃ']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mmcut(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gNW40NoQkxfe",
        "outputId": "273ed7f6-d1d7-46b3-d7f0-4542b3920ff1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['จุ๋ม']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mmcut('จุ๋ม')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "yi4j1CWok1sk",
        "outputId": "d232ed5b-b9c1-4c07-c9f5-5050736f15cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ไทยปน', ' ', 'english', ' ', 'ก็ได้นะ']"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mmcut('ไทยปน english ก็ได้นะ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL1-wFb11T3b"
      },
      "source": [
        "# สรุปรวม\n",
        "copy code จากข้างบน เอาเฉพาะที่ใช้จริง"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6ZTCdI041V5e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "from heapq import heappush, heappop  # for priority queue\n",
        "from marisa_trie import Trie\n",
        "\n",
        "wordlist = [li.strip() for li in open('./khmer_dictionary.txt', 'r', encoding='utf-8')]\n",
        "trie = Trie(wordlist)\n",
        "\n",
        "# ช่วยตัดพวกภาษาอังกฤษ เป็นต้น\n",
        "pat_eng = re.compile(r'''(?x)\n",
        "[-a-zA-Z]+|   # english\n",
        "\\d[\\d,\\.]*|   # number\n",
        "[ \\t]+|       # space\n",
        "\\r?\\n         # newline\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of khmer vowels in unicode\n",
        "# vowels = '឴឵នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "QIuS1Edilb1-"
      },
      "outputs": [],
      "source": [
        "# TCC\n",
        "pat_tcc = \"\"\"\\\n",
        "เc็c\n",
        "เcctาะ\n",
        "เccีtยะ\n",
        "เccีtย(?=[เ-ไก-ฮ]|$)\n",
        "เccอะ\n",
        "เcc็c\n",
        "เcิc์c\n",
        "เcิtc\n",
        "เcีtยะ?\n",
        "เcืtอะ?\n",
        "เc[ิีุู]tย(?=[เ-ไก-ฮ]|$)\n",
        "เctา?ะ?\n",
        "cัtวะ\n",
        "c[ัื]tc[ุิะ]?\n",
        "c[ิุู]์\n",
        "c[ะ-ู]t\n",
        "c็\n",
        "ct[ะาำ]?\n",
        "แc็c\n",
        "แcc์\n",
        "แctะ\n",
        "แcc็c\n",
        "แccc์\n",
        "โctะ\n",
        "[เ-ไ]ct\n",
        "\"\"\".replace('c','[ก-ฮ]').replace('t', '[่-๋]?').split()\n",
        "\n",
        "khm_pat_tcc = \"\"\"\\\n",
        "s[ក-ឯ]\n",
        "s[ឰ-។]\n",
        "s[០-៩]\n",
        "s[[ក-ឯ]s\n",
        "s[ឰ-។]s\n",
        "s[៕-៚]s\n",
        "s[៛-៞]s\n",
        "s[០-៩]s\n",
        "c[ក-ឯ]\n",
        "c[ក-ឯ]c\n",
        "\"\"\".replace('s', '[\\u17b6 \\u17b7 \\u17b8 \\u17b9 \\u17ba \\u17bb \\u17bc \\u17bd \\u17be \\u17bf \\u17c0 \\u17c1 \\u17c2 \\u17c3 \\u17c4 \\u17c5 \\u17c6 \\u17c7 \\u17c8 ]').replace('c', '[ក-ឯ]').split()\n",
        "\n",
        "\n",
        "def tcc(w):\n",
        "    p = 0\n",
        "    pat = re.compile(\"|\".join(khm_pat_tcc))\n",
        "    while p<len(w):\n",
        "        m = pat.match(w[p:])\n",
        "        if m:\n",
        "            n = m.span()[1]\n",
        "        else:\n",
        "            n = 1\n",
        "        yield w[p:p+n]\n",
        "        p += n\n",
        "\n",
        "def tcc_pos(text):\n",
        "    p_set = set()\n",
        "    p = 0\n",
        "    for w in tcc(text):\n",
        "        p += len(w)\n",
        "        p_set.add(p)\n",
        "    return p_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zcX9oa7rl8Fr"
      },
      "outputs": [],
      "source": [
        "def serialize(words_at, p, p2):\n",
        "  # find path ทั้งหมด แบบ depth first\n",
        "  if p in words_at:\n",
        "    for w in words_at[p]:\n",
        "      p_ = p + len(w)\n",
        "      if p_== p2:\n",
        "        yield [w]\n",
        "      elif p_ < p2:\n",
        "        for path in serialize(words_at, p_, p2):\n",
        "          yield [w]+path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "CS5tOC3kmjHV"
      },
      "outputs": [],
      "source": [
        "def onecut(text):\n",
        "  words_at = defaultdict(list)  # main data structure\n",
        "  allow_pos = tcc_pos(text)     # ตำแหน่งที่ตัด ต้องตรงกับ tcc\n",
        "\n",
        "  q = [0]       # min-heap queue\n",
        "  last_p = 0    # last position for yield\n",
        "  while q[0] < len(text):\n",
        "      p = heappop(q)\n",
        "\n",
        "      for w in trie.prefixes(text[p:]):\n",
        "          p_ = p + len(w)\n",
        "          if p_ in allow_pos:  # เลือกที่สอดคล้อง tcc\n",
        "            words_at[p].append(w)\n",
        "            if p_ not in q:\n",
        "              heappush(q, p_)\n",
        "\n",
        "      # กรณี length 1 คือ ไม่กำกวมแล้ว ส่งผลลัพธ์ก่อนนี้คืนได้\n",
        "      if len(q)==1:\n",
        "          paths = serialize(words_at, last_p, q[0])\n",
        "          for w in min(paths, key=len):\n",
        "            yield w\n",
        "          last_p = q[0]\n",
        "\n",
        "      # กรณี length 0  คือ ไม่มีใน dict\n",
        "      if len(q)==0:\n",
        "          m = pat_eng.match(text[p:])\n",
        "          if m: # อังกฤษ, เลข, ว่าง\n",
        "              i = p + m.end()\n",
        "          else: # skip น้อยที่สุด ที่เป็นไปได้\n",
        "              for i in range(p+1, len(text)):\n",
        "                  if i in allow_pos:   # ใช้ tcc ด้วย ทั้งจุดเริ่มและจบ\n",
        "                      ww = [w for w in trie.prefixes(text[i:]) if (i+len(w) in allow_pos)]\n",
        "                      m = pat_eng.match(text[i:])\n",
        "                      if ww or m:\n",
        "                          break\n",
        "              else:\n",
        "                  i = len(text)\n",
        "          w = text[p:i]\n",
        "          words_at[p].append(w)\n",
        "          yield w\n",
        "          last_p = i\n",
        "          heappush(q, i)\n",
        "\n",
        "# ช่วยให้ไม่ต้องพิมพ์ยาวๆ\n",
        "def mmcut(text):\n",
        "  return list(onecut(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iDik5nhDm52P",
        "outputId": "92a80576-76ee-4163-af87-6aa8fa793609"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/wr/pmsgcfqj1q94s8k_nr2yjrrw0000gn/T/ipykernel_49297/492616637.py:46: FutureWarning: Possible nested set at position 179\n",
            "  pat = re.compile(\"|\".join(khm_pat_tcc))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['នែក',\n",
              " 'ន',\n",
              " 'ៃដៃឬ',\n",
              " 'ជើង',\n",
              " 'ដែល',\n",
              " 'តភ្ជាប់',\n",
              " 'ព',\n",
              " 'ីប្រអ',\n",
              " 'ប',\n",
              " '់',\n",
              " 'ដ',\n",
              " 'ៃទៅកំភួន',\n",
              " 'ដៃ']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mmcut('នែកនៃដៃឬជើងដែលតភ្ជាប់ពីប្រអប់ដៃទៅកំភួនដៃ')   # ทำงานได้ถูกต้อง"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KZWT01wRnIy9",
        "outputId": "797fad26-7ba2-4f94-d77c-e22d9f9960e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ជើង']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mmcut('ជើង')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgRDHBONsH4m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Fnz873rCjwdH",
        "W8qOGjNIoEIh",
        "pbF5DamyoWWY",
        "Wkv6s-gu1aCN",
        "Oh2iZfSicoJr",
        "c0iyC9PQQrRH",
        "9tlRicYuaMM4",
        "gr-CCHgIaups"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
